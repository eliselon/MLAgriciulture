---
title: "Prédictions de cultures"
author: "Elise Lonchampt, Emma Da Costa Silva, Maud Lesage"
date: "2024-10-12"
output: html_document
---

# Présentation du jeu de données

```{r importation jeu de données}
dta <- read.table('Crop_recommendation.csv', sep = ';', header = TRUE, stringsAsFactors = TRUE)
summary(dta)
```
<<<<<<< HEAD

=======
>>>>>>> Elise
Le jeu de données collecté en Inde, un pays où 70 % de la population pratique l’agriculture, contribuant à environ 17 % du PIB national. Le jeu de données est composé de huit variables : sept variables physico-chimiques des sols et une variable décrivant le type de culture adaptée (Katarya et al., 2020). La variable culture présente 22 modalités et 100 observations par modalités. Le jeu de données est donc équilibré. Toutefois, malgré l'équilibrage en termes de taille des classes, certaines difficultés peuvent encore se poser.

# Prédiction de la meilleure culture pour un profil de sol 

<<<<<<< HEAD
=======
## Modèle de régression logistique

>>>>>>> Elise
```{r GLM}
require(class)
require(caret)

set.seed(123)

trainIndex <- createDataPartition(dta$label, p = 0.75, list = FALSE)

data.train <- dta[trainIndex, ]
data.test <- dta[-trainIndex, ]

ctrl <- trainControl(method = "cv", number = 10) # 10-fold cross-validation

# Entraîner le modèle glm avec la validation croisée
glm_model <- train(label ~ ., data = data.train, method = "multinom", trControl = ctrl)

# Prédire
pred_glm <- predict(glm_model, newdata = data.test)

# Accuracy
conf_matrix <- confusionMatrix(pred_glm, data.test$label)
confusionMatrix(pred_glm, data.test$label)
accuracy <- conf_matrix$overall['Accuracy']
print(paste("Accuracy: ", accuracy))
```

Accuracy égale à 0.86.

## Modèle KNN

```{r Knn}
tuneGrid <- expand.grid(k = 1:20)

set.seed(123)

# Entraîner le modèle Knn avec la validation croisée
knn_model <- train(label ~ .,
                   data = data.train, 
                   method = "knn", 
                   tuneGrid = tuneGrid, ## test les valeurs de k de 1 à 20
                   trControl = ctrl)

# Meilleur k trouvé
best_k <- knn_model$bestTune
print(best_k)

# Prédire avec le meilleur modèle
pred_knn <- predict(knn_model, newdata = data.test)

# Accuracy
conf_matrix <- confusionMatrix(pred_knn, data.test$label)
confusionMatrix(pred_knn, data.test$label)
accuracy <- conf_matrix$overall['Accuracy']
print(paste("Accuracy: ", accuracy))
```

<<<<<<< HEAD
Accuracy égale à 0,978.
=======
Accuracy égale à 0,98.
>>>>>>> Elise

## Random Forest

Réalisé sur python

# Test de la capacité des modèles à différencier les cultures similaires

## Similarité entre les cultures

Etant donné le grand nombre de culture, il est probable que certaines cultures soient très similaires en termes de caractéristiques mesurées. Par exemple, deux cultures qui se développent dans des conditions de sol et climatiques très proches pourraient partager des profils de sol quasi identiques. Cela rendrait difficile la distinction entre ces cultures pour le modèle.

```{r}
require(FactoMineR)
resPCA2 <- PCA(dta, scale.unit = TRUE, quali.sup = 8)
plot(resPCA2,habillage=8,label="quali")
```

## Choix de 5 cultures similaires suite à une classification ascendante hiérarchique

Une classification ascendante hiérarchique est utilisée pour déterminer quelles cultures sont similaires. L'objectif est par la suite de choisir un sous-ensembles de cultures similaires pour évaluer la capacité des modèles à différencier les cultures similaires.

```{r CAH}
library (FactoMineR)

res_PCA <- PCA(dta[,-8], scale.unit = TRUE)

res_HCPC <- HCPC(res_PCA, nb.clust = 3) ## 3 clusters

dta2 <- dta
dta2$clust <- res_HCPC$data.clust$clust
table_clusters_label <- table(dta2$label, dta2$clust)
print(table_clusters_label)
## Cluster 1 = Banana, Coconut, Coffee, Cotton, Jute, Maize, Muskmelon, Orange, Papaya, Pomegrade, Rice, Watermelon
## Cluster 2 = Blackgram, Chickpea, Kidneybeans, Lentil, Mango, Mothbeans, Mungbean, Pigeonpeas
## Cluster 3 = Apple, Grapes

res_HCPC$desc.var$quanti$`1`
res_HCPC$desc.var$quanti$`2`
res_HCPC$desc.var$quanti$`3` 

resPCA2 <- PCA(dta[,-9], scale.unit = TRUE, quali.sup = 8)
plot(resPCA2,habillage=8,label="quali")
```

Nous obtenons ici trois cluster différents. Le premier cluster inclut les fruits tropicaux et les cultures de rente, tels que la banane, la noix de coco, et le café, qui prospèrent dans des conditions de sol humide, riche en azote, avec des précipitations importantes. Ces cultures sont adaptées à des climats tropicaux où l'abondance d'eau et un sol bien drainé sont essentiels pour une croissance optimale. Le deuxième cluster regroupe la mangue et les légumineuses comme les pois chiches, les haricots mungo. Ces plantes préfèrent un sol relativement pauvre en azote, bien drainé, et faiblement humide. Le dernier cluster comprend des cultures tempérées comme la pomme et le raisin, qui préfèrent un sol riche en potassium et en phosphore, mais pauvre en azote.

Nous avons sélectionné 5 cultures très similaires pour évaluer la capacité de prédiction de nos modèles dans le cas de situations où les cultures présentent des caractéristiques agronomiques et environnementales proches. L'objectif est de vérifier si les modèles peuvent encore discriminer correctement dans des contextes où les variations entre les cultures sont faibles, simulant ainsi des choix agricoles plus délicats à effectuer. Pour ce faire nous avons choisi les cultures suivantes : le jute, le riz, le maïs, le cotton et le café. Ces cultures prospèrent dans les climats tropicaux chauds et humides.

## Prédiction avec le sous-ensemble de cultures similaires

```{r Cultures similaires}
# Modèle de régression logistique

cultures_similaires <- c("coffee", "cotton", "maize", "rice", "jute")

filtered_test_data <- data.test[data.test$label %in% cultures_similaires, ]
filtered_test_data <- droplevels(filtered_test_data)

# Prédiction avec le sous-ensemble de culture
pred_glm_filtered <- predict(glm_model, newdata = filtered_test_data)

# Matrice de confusion et accuracy
pred_glm_filtered <- factor(pred_glm_filtered, levels = levels(filtered_test_data$label))
conf_matrix_filtered <- confusionMatrix(pred_glm_filtered, filtered_test_data$label)
print(conf_matrix_filtered)
accuracy_filtered <- conf_matrix_filtered$overall['Accuracy']

# Modèle KNN

set.seed(123)

cultures_similaires <- c("coffee", "cotton", "maize", "rice", "jute")

filtered_test_data <- data.test[data.test$label %in% cultures_similaires, ]
filtered_test_data <- droplevels(filtered_test_data)

# Prédiction avec le sous-ensemble de culture
pred_knn_filtered <- predict(knn_model, newdata = filtered_test_data)

# Matrice de confusion et accuracy
pred_knn_filtered <- factor(pred_knn_filtered, levels = levels(filtered_test_data$label))
conf_matrix_filtered <- confusionMatrix(pred_knn_filtered, filtered_test_data$label)
print(conf_matrix_filtered)
accuracy_filtered <- conf_matrix_filtered$overall['Accuracy']

# Modèle Random Forest sur python
```

Nous pouvons constater que les accuracy liées aux modèles ont diminué. En effet, pour le modèle glm elle passe de 0,86 à 0,84. Pour le modèle KNN, elle diminue de 6%, passant de 0,98 à 0,92.

En examinant plus en attentivement la matrice de confusion pour le modèle KNN, on observe quelques erreurs de prédiction, en particulier pour les classes maïs, jute, et riz. Bien que ces erreurs restent limitées, la classe riz est confondue avec la classe jute dans 25% des cas. Le modèle semble donc trouver des difficultés à différencier ces deux cultures. Malgré ces erreurs, le modèle knn présente une accuracy gravitant autour de 0,93. Nous pouvons donc conclure que le modèle discrimine efficacement les différentes cultures.

Parler de la spécificité et de la sensibilité

Comparer les modèles entre eux et avec Random Forest

# Sélection des variables dans le modèle

## Corrélation entre les variables 

```{r}
library (tidyverse)
library(ggcorrplot)

dta[,-8] %>% cor() %>% round(1) %>% ggcorrplot(type = "lower", lab = TRUE)
```

## Importance des variables dans les modèles

```{r Var}
set.seed(123)

# Évaluer l'importance des variables avec RFE
rfe_ctrl <- rfeControl(functions = rfFuncs, # Pour Random Forest par exemple, cela peut aussi être "lmFuncs" pour la régression linéaire
                       method = "cv", 
                       number = 10)

# Effectuer l'élimination récursive des variables
rfe_results <- rfe(data.train[, -ncol(data.train)], data.train$label, 
                   sizes = c(1:7),  # Teste toutes les tailles de 1 à 7
                   rfeControl = rfe_ctrl)

# Résumé des résultats
print(rfe_results)

# Visualiser l'importance des variables
plot(rfe_results, type = c("g", "o"))

# Variables sélectionnées
selected_vars <- predictors(rfe_results)
print(selected_vars)
```
# Conclusion
