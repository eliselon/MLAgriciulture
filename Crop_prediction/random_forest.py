# -*- coding: utf-8 -*-
"""Random_Forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zv0MQLl4Cd_OshifIA72-ETZbyKtmbtw
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay
from sklearn.tree import plot_tree
from sklearn.feature_selection import RFE

dta = pd.read_csv('Crop_recommendation.csv', sep=';')

"""### **Random forest sur l'ensemble des cultures :**"""

# Séparer les variables explicatives et la variable cible
X = dta.drop(columns='label')  # Toutes les colonnes sauf 'label'
y = dta['label']

# Diviser en jeu d'entraînement et de test (75%/25%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)

# Modèle Random Forest avec validation croisée à 10 folds
rf_model = RandomForestClassifier(random_state=42)
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Afficher la performance moyenne pendant la validation croisée
scores = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='accuracy')
print(f"Accuracy moyenne: {scores.mean():.4f}")

# Entraîner le modèle sur l'ensemble d'entraînement
rf_model.fit(X_train, y_train)

# Faire des prédictions sur l'ensemble de test
y_pred = rf_model.predict(X_test)

# Évaluer la performance avec l'accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy sur l'ensemble de test: {accuracy:.4f}")

# Afficher la matrice de confusion
unique_labels = y.unique()
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(20, 8))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=unique_labels)
disp.plot(cmap=plt.cm.Blues, ax=plt.gca())
plt.title("Matrice de confusion - Ensemble des cultures")
plt.xticks(rotation=90)
plt.show()

# Afficher l'importance des variables
importances = rf_model.feature_importances_
feature_importance = pd.Series(importances, index=X.columns)
feature_importance.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6))
plt.title('Importance des variables dans le modèle Random Forest pour l\'ensemble des cultures')
plt.show()

"""**Test du meilleur modèle :**

"""

# Initialiser un dictionnaire pour stocker les résultats
results = {}

# Boucler sur le nombre de variables à sélectionner (de 1 jusqu'au nombre total de variables)
for num_features in range(1, X_train.shape[1] + 1):
    # Mettre en place RFE pour tester avec num_features variables
    rfe = RFE(estimator=rf_model, n_features_to_select=num_features, step=1)

    # Appliquer RFE pour ajuster le modèle
    rfe.fit(X_train, y_train)

    #Résumer les résultats : Afficher les variables sélectionnées
    selected_features = X.columns[rfe.support_]
    print(f"Variables sélectionnées avec {num_features} variables: {list(selected_features)}")

    #Évaluer les performances du modèle sur l'ensemble de test
    y_pred = rfe.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy avec {num_features} variables sélectionnées: {accuracy}")

    # Stocker le résultat dans le dictionnaire
    results[num_features] = accuracy

#Trouver le nombre optimal de variables
best_num_features = max(results, key=results.get)
best_accuracy = results[best_num_features]

# Afficher le meilleur résultat
print(f"Nombre optimal de variables: {best_num_features}")
print(f"Meilleure accuracy: {best_accuracy}")

# Optionnel : Afficher les performances pour chaque nombre de variables
plt.figure(figsize=(10, 6))
plt.plot(list(results.keys()), list(results.values()), marker='o')
plt.title('Accuracy pour chaque nombre de variables sélectionnées avec RFE')
plt.xlabel('Nombre de variables')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()

# Visualisation d'un arbre de décision
plt.figure(figsize=(20, 10))
plot_tree(rf_model.estimators_[0], feature_names=X.columns, class_names=rf_model.classes_, filled=True)
plt.title('Visualisation d\'un arbre de décision')
plt.show()

"""### **Random forest sur les sous-ensembles de cultures similaires :**"""

# Filtrer les cultures similaires (Coffee, Cotton, Maize, Rice, Jute)
cultures_similaires = ['coffee', 'cotton', 'maize', 'rice', 'jute']
filtered_data = y_test.isin(cultures_similaires)

# Réassigner X et y pour les sous-ensembles de cultures similaires
X_test_filtered = X_test[filtered_data]
y_test_filtered = y_test[filtered_data]

# Prédictions sur l'ensemble de test filtré
pred_filtered = rf_model.predict(X_test_filtered)

# Évaluer la performance avec l'accuracy sur cet ensemble filtré
accuracy_filtered = accuracy_score(y_test_filtered, pred_filtered)
print(f"Accuracy pour les cultures similaires : {accuracy_filtered:.4f}")

# Matrice de confusion pour le sous-ensemble
conf_matrix_filtered = confusion_matrix(y_test_filtered, pred_filtered, labels=cultures_similaires)

disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_filtered, display_labels=cultures_similaires)
disp.plot(cmap=plt.cm.Blues)
plt.title("Matrice de confusion - Cultures similaires")
plt.show()

# Convertir la matrice de confusion en DataFrame pour un affichage plus clair
cm_df = pd.DataFrame(conf_matrix_filtered, index=cultures_similaires, columns=cultures_similaires)

# Calcul de la sensibilité et de la spécificité par classe
sensitivity = {}
specificity = {}

for cls in cultures_similaires:
    TP = cm_df.loc[cls, cls]  # Vrais positifs
    FN = cm_df.loc[cls].sum() - TP  # Faux négatifs
    TN = cm_df.values.sum() - (cm_df.loc[cls].sum())  # Vrais négatifs
    FP = cm_df[cls].sum() - TP  # Faux positifs

    # Calculer la sensibilité et la spécificité
    sensitivity[cls] = TP / (TP + FN) if (TP + FN) > 0 else 0
    specificity[cls] = TN / (TN + FP) if (TN + FP) > 0 else 0

# Afficher les résultats
sensitivity_df = pd.Series(sensitivity)
specificity_df = pd.Series(specificity)

print("Sensibilité par classe:")
print(sensitivity_df)

print("\nSpécificité par classe:")
print(specificity_df)

# Afficher l'importance des variables
importances_similar = rf_model.feature_importances_
feature_importance_similar = pd.Series(importances_similar, index=X_test_filtered.columns)
feature_importance_similar.sort_values(ascending=False).plot(kind='bar', figsize=(10, 6))
plt.title('Importance des variables dans le modèle Random Forest (cultures similaires)')
plt.show()

"""**Test du meilleur modèle :**"""

# Initialiser un dictionnaire pour stocker les résultats
results = {}

# Boucler sur le nombre de variables à sélectionner (de 1 jusqu'au nombre total de variables)
for num_features in range(1, X_train.shape[1] + 1):
    # Mettre en place RFE pour tester avec num_features variables
    rfe = RFE(estimator=rf_model, n_features_to_select=num_features, step=1)

    # Appliquer RFE pour ajuster le modèle
    rfe.fit(X_train, y_train)

    # Résumer les résultats : Afficher les variables sélectionnées
    selected_features = X.columns[rfe.support_]
    print(f"Variables sélectionnées avec {num_features} variables: {list(selected_features)}")

    # Évaluer les performances du modèle sur l'ensemble de test
    X_test_selected = X_test[filtered_data]
    y_pred = rfe.predict(X_test_selected)

    # Calculer l'accuracy
    accuracy = accuracy_score(y_test_filtered, y_pred)
    print(f"Accuracy avec {num_features} variables sélectionnées: {accuracy:.4f}")

    # Stocker le résultat dans le dictionnaire
    results[num_features] = accuracy

# Trouver le nombre optimal de variables
best_num_features = max(results, key=results.get)
best_accuracy = results[best_num_features]

# Afficher le meilleur résultat
print(f"Nombre optimal de variables: {best_num_features}")
print(f"Meilleure accuracy: {best_accuracy:.4f}")

# Optionnel : Afficher les performances pour chaque nombre de variables
plt.figure(figsize=(10, 6))
plt.plot(list(results.keys()), list(results.values()), marker='o')
plt.title('Accuracy pour chaque nombre de variables sélectionnées avec RFE (Cultures similaires)')
plt.xlabel('Nombre de variables')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()

# Visualisation d'un arbre de décision
plt.figure(figsize=(150, 50))
plot_tree(rf_model.estimators_[0],
          feature_names=X_test_filtered.columns,
          class_names=rf_model.classes_,
          filled=True)
plt.title('Visualisation d\'un arbre de décision (cultures similaires)')
plt.show()